{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a165949",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-17T08:56:24.180419Z",
     "iopub.status.busy": "2022-09-17T08:56:24.179832Z",
     "iopub.status.idle": "2022-09-17T08:56:24.214731Z",
     "shell.execute_reply": "2022-09-17T08:56:24.212199Z",
     "shell.execute_reply.started": "2022-09-17T08:56:24.180306Z"
    },
    "papermill": {
     "duration": 0.016694,
     "end_time": "2022-09-17T10:04:40.860200",
     "exception": false,
     "start_time": "2022-09-17T10:04:40.843506",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**In this notebook, i'm going to explain L2 regularization and show an example of CNN model being regularized** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f13d572",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-17T10:04:40.922776Z",
     "iopub.status.busy": "2022-09-17T10:04:40.915321Z",
     "iopub.status.idle": "2022-09-17T10:04:48.372348Z",
     "shell.execute_reply": "2022-09-17T10:04:48.371064Z"
    },
    "papermill": {
     "duration": 7.472957,
     "end_time": "2022-09-17T10:04:48.375602",
     "exception": false,
     "start_time": "2022-09-17T10:04:40.902645",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "        # This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from tensorflow import keras as ks\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.regularizers import l2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "#import os\n",
    "#for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    " #   for filename in filenames:\n",
    "  #      print(os.path.join(dirname, filename))\n",
    "        \n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac336974",
   "metadata": {
    "papermill": {
     "duration": 0.006447,
     "end_time": "2022-09-17T10:04:48.391467",
     "exception": false,
     "start_time": "2022-09-17T10:04:48.385020",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# L2 Regularization (for a CNN example)\n",
    "##### also called simply “weight decay\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c5379d",
   "metadata": {
    "papermill": {
     "duration": 0.006319,
     "end_time": "2022-09-17T10:04:48.404226",
     "exception": false,
     "start_time": "2022-09-17T10:04:48.397907",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**If you suspect your neural network is overfitting your data, \n",
    "that is, you have a high variance problem, one of the first things you should try is probably regularization.**  \n",
    "\n",
    "In L2, we have:\n",
    "  \n",
    "![L2](https://i.ibb.co/b3Dp6mL/L2.png) it comes **to adding a cost** to the loss function for large weights\n",
    "\n",
    "Here, **lambda** is the regularization parameter. It is the hyperparameter whose value is optimized for better results. L2 regularization is also known as weight decay as it forces the weights to decay towards zero (but not exactly zero).  \n",
    "**By default, no regularizer is used in any layers.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7d64f8",
   "metadata": {
    "papermill": {
     "duration": 0.006358,
     "end_time": "2022-09-17T10:04:48.417442",
     "exception": false,
     "start_time": "2022-09-17T10:04:48.411084",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "A weight regularizer can be added to each layer when the layer is defined in a Keras model.  \n",
    "**A weight regularizer can be added to each layer when the layer is defined in a Keras model.**\n",
    "\n",
    "This is achieved by setting the kernel_regularizer argument on each layer. A separate regularizer can also be used for the bias via the bias_regularizer argument, although this is less often used.\n",
    "\n",
    "Let’s look at some examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8364c02e",
   "metadata": {
    "papermill": {
     "duration": 0.006532,
     "end_time": "2022-09-17T10:04:48.430440",
     "exception": false,
     "start_time": "2022-09-17T10:04:48.423908",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Weight Regularization for Dense Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13ea078b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-17T10:04:48.445731Z",
     "iopub.status.busy": "2022-09-17T10:04:48.444363Z",
     "iopub.status.idle": "2022-09-17T10:04:48.450615Z",
     "shell.execute_reply": "2022-09-17T10:04:48.449443Z"
    },
    "papermill": {
     "duration": 0.01658,
     "end_time": "2022-09-17T10:04:48.453271",
     "exception": false,
     "start_time": "2022-09-17T10:04:48.436691",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## example of l2 on a dense layer\n",
    "##from keras.layers import Dense\n",
    "##from keras.regularizers import l2\n",
    "\n",
    "##model.add(Dense(32, kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0f5a8c",
   "metadata": {
    "papermill": {
     "duration": 0.007266,
     "end_time": "2022-09-17T10:04:48.467018",
     "exception": false,
     "start_time": "2022-09-17T10:04:48.459752",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "kernel_regularizer: Regularizer to apply a penalty on the layer's kernel  \n",
    "bias_regularizer: Regularizer to apply a penalty on the layer's bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2959a9",
   "metadata": {
    "papermill": {
     "duration": 0.00651,
     "end_time": "2022-09-17T10:04:48.480125",
     "exception": false,
     "start_time": "2022-09-17T10:04:48.473615",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Weight Regularization for Convolutional Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce2db91",
   "metadata": {
    "papermill": {
     "duration": 0.006544,
     "end_time": "2022-09-17T10:04:48.493132",
     "exception": false,
     "start_time": "2022-09-17T10:04:48.486588",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "Like the Dense layer, the Convolutional layers (e.g. Conv1D and Conv2D) also use the kernel_regularizer and bias_regularizer arguments to define a regularizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fafcfcd9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-17T10:04:48.510278Z",
     "iopub.status.busy": "2022-09-17T10:04:48.508349Z",
     "iopub.status.idle": "2022-09-17T10:04:48.515065Z",
     "shell.execute_reply": "2022-09-17T10:04:48.513741Z"
    },
    "papermill": {
     "duration": 0.017297,
     "end_time": "2022-09-17T10:04:48.517601",
     "exception": false,
     "start_time": "2022-09-17T10:04:48.500304",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# example of l2 on a convolutional layer\n",
    "#from keras.layers import Conv2D\n",
    "#from keras.regularizers import l2\n",
    "\n",
    "#model.add(Conv2D(32, (3,3), kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415a52b6",
   "metadata": {
    "papermill": {
     "duration": 0.006605,
     "end_time": "2022-09-17T10:04:48.530965",
     "exception": false,
     "start_time": "2022-09-17T10:04:48.524360",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Weight Regularization for Recurrent Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed61af4",
   "metadata": {
    "papermill": {
     "duration": 0.006375,
     "end_time": "2022-09-17T10:04:48.543790",
     "exception": false,
     "start_time": "2022-09-17T10:04:48.537415",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Example for Recccurrent Layers :   \n",
    "LSTM layer  \n",
    "GRU layer  \n",
    "SimpleRNN layer  \n",
    "TimeDistributed layer  \n",
    "Bidirectional layer  \n",
    "ConvLSTM1D layer  \n",
    "ConvLSTM2D layer  \n",
    "ConvLSTM3D layer  \n",
    "Base RNN layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd740ece",
   "metadata": {
    "papermill": {
     "duration": 0.006877,
     "end_time": "2022-09-17T10:04:48.557231",
     "exception": false,
     "start_time": "2022-09-17T10:04:48.550354",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "Recurrent layers like the LSTM offer more flexibility in regularizing the weights.\n",
    "\n",
    "The input, recurrent, and bias weights can all be regularized separately via the kernel_regularizer, recurrent_regularizer, and bias_regularizer arguments.\n",
    "\n",
    "The example below sets an l2 regularizer on an LSTM recurrent layer:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8c282f",
   "metadata": {
    "papermill": {
     "duration": 0.006069,
     "end_time": "2022-09-17T10:04:48.569668",
     "exception": false,
     "start_time": "2022-09-17T10:04:48.563599",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1484aee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-17T10:04:48.584606Z",
     "iopub.status.busy": "2022-09-17T10:04:48.584254Z",
     "iopub.status.idle": "2022-09-17T10:04:48.589689Z",
     "shell.execute_reply": "2022-09-17T10:04:48.588312Z"
    },
    "papermill": {
     "duration": 0.016439,
     "end_time": "2022-09-17T10:04:48.592428",
     "exception": false,
     "start_time": "2022-09-17T10:04:48.575989",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# example of l2 on an lstm layer\n",
    "#from keras.layers import LSTM\n",
    "#from keras.regularizers import l2\n",
    "#model.add(LSTM(32, kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01), bias_regularizer=l2(0.01)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326e1945",
   "metadata": {
    "papermill": {
     "duration": 0.006285,
     "end_time": "2022-09-17T10:04:48.605767",
     "exception": false,
     "start_time": "2022-09-17T10:04:48.599482",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Which layers should i add L2 regularization ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273b685d",
   "metadata": {
    "papermill": {
     "duration": 0.006306,
     "end_time": "2022-09-17T10:04:48.618640",
     "exception": false,
     "start_time": "2022-09-17T10:04:48.612334",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "it seems to be an convention to add L2 regularization for each layer, as long as you didn’t set a too large weight for that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e736f55",
   "metadata": {
    "papermill": {
     "duration": 0.0061,
     "end_time": "2022-09-17T10:04:48.631389",
     "exception": false,
     "start_time": "2022-09-17T10:04:48.625289",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "To increase the regularization of a model(=the effect of the L_2 penalization) one of the actions that you can do **is increasing the value of the hyperparameter.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c410e8f",
   "metadata": {
    "papermill": {
     "duration": 0.006338,
     "end_time": "2022-09-17T10:04:48.644631",
     "exception": false,
     "start_time": "2022-09-17T10:04:48.638293",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfbfdcd",
   "metadata": {
    "papermill": {
     "duration": 0.006076,
     "end_time": "2022-09-17T10:04:48.657035",
     "exception": false,
     "start_time": "2022-09-17T10:04:48.650959",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "to be added on the dropout part ::  \n",
    "Typically there is no need to to add dropout for every layer. In most of the popular CNN structure, you may only add dropout at each (or only the last) full connected layer.\n",
    "\n",
    "Adding too much dropout for regularization will severely slow down the convergence rate, and change over-fitting to under-fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56f1d1f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-17T10:04:48.673136Z",
     "iopub.status.busy": "2022-09-17T10:04:48.671293Z",
     "iopub.status.idle": "2022-09-17T10:04:53.251127Z",
     "shell.execute_reply": "2022-09-17T10:04:53.249710Z"
    },
    "papermill": {
     "duration": 4.590198,
     "end_time": "2022-09-17T10:04:53.253944",
     "exception": false,
     "start_time": "2022-09-17T10:04:48.663746",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-17 10:04:49.171130: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-17 10:04:49.310382: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-17 10:04:49.314490: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-17 10:04:49.319560: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-09-17 10:04:49.324918: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-17 10:04:49.328906: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-17 10:04:49.332649: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-17 10:04:52.487553: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-17 10:04:52.491634: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-17 10:04:52.495604: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-09-17 10:04:52.499447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15401 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    }
   ],
   "source": [
    "model0 = ks.models.Sequential()\n",
    "model0.add(ks.layers.Dense(4, input_shape=(64, 64, 1))) #units=4(we define how many outputs we want)\n",
    "model0.add(ks.layers.Dense(8, input_shape=(64, 64, 1)))\n",
    "model0.add(ks.layers.Dense(8, input_shape=(64, 64, 1)))\n",
    "model0.add(ks.layers.Conv2D(64,(3, 3), activation='relu')) \n",
    "       \n",
    "model0.add(ks.layers.MaxPooling2D(pool_size=2, strides=2))\n",
    "model0.add(ks.layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model0.add(ks.layers.MaxPooling2D(2, 2)) \n",
    "       \n",
    "model0.add(ks.layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "model0.add(ks.layers.MaxPooling2D(2, 2))\n",
    "model0.add(ks.layers.Conv2D(512, (3, 3), activation='relu'))\n",
    "model0.add(ks.layers.MaxPooling2D(2, 2))\n",
    "model0.add(ks.layers.Dropout(0.2))\n",
    "model0.add(ks.layers.Flatten())\n",
    "\n",
    "model0.add(ks.layers.Dense(1024, activation='relu'))\n",
    "model0.add(ks.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model0.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76aba223",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-17T10:04:53.269951Z",
     "iopub.status.busy": "2022-09-17T10:04:53.269560Z",
     "iopub.status.idle": "2022-09-17T10:05:02.624257Z",
     "shell.execute_reply": "2022-09-17T10:05:02.622870Z"
    },
    "papermill": {
     "duration": 9.366837,
     "end_time": "2022-09-17T10:05:02.627958",
     "exception": false,
     "start_time": "2022-09-17T10:04:53.261121",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#This is more explained on my notebook: https://www.kaggle.com/code/houssemaminetouihri/implementation-of-cnn-s-models-and-comparison-betw#Importing-necessary-libraries\n",
    "#Reading the data\n",
    "train=pd.read_csv(\"../input/sign-recognition/Train.csv\")\n",
    "test=pd.read_csv(\"../input/sign-recognition/Test.csv\")\n",
    "#Drop ID column and define train_y , train_x , test_x\n",
    "train_y=train['Target'].astype('float32')\n",
    "train_x=train.drop(['Target','ID'],axis=1).astype('int32')\n",
    "test_x=test.drop(['ID'],axis=1).astype('int32')\n",
    "#One Hot Encoding for train_y\n",
    "train_y=ks.utils.to_categorical(train_y,10)\n",
    "#Reshape the size of images and normalize them\n",
    "train_x=train_x.values.reshape(-1,64,64,1) #.values return an array #-1:to convert it to 1-D \n",
    "train_x=train_x/255.0\n",
    "test_x=test_x.values.reshape(-1,64,64,1)\n",
    "test_x/255.0\n",
    "#split\n",
    "x_train , x_test, y_train , y_test=train_test_split(train_x, train_y , test_size=0.15)\n",
    "#Generating new images\n",
    "datagenerator = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "train_generator = datagenerator.flow(x_train,y_train,)\n",
    "validation_generator = datagenerator.flow(x_test, y_test)\n",
    "model0.compile(optimizer=ks.optimizers.Adam(),loss='categorical_crossentropy',metrics=['acc'])\n",
    "class myCallback(ks.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('acc')>0.85) and (logs.get('val_acc')>0.85):\n",
    "            print('\\n reached 84% accuarcy so stopping training')\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fc0037d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-17T10:05:02.652986Z",
     "iopub.status.busy": "2022-09-17T10:05:02.652401Z",
     "iopub.status.idle": "2022-09-17T10:12:10.231658Z",
     "shell.execute_reply": "2022-09-17T10:12:10.230370Z"
    },
    "papermill": {
     "duration": 427.595035,
     "end_time": "2022-09-17T10:12:10.234807",
     "exception": false,
     "start_time": "2022-09-17T10:05:02.639772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      "2022-09-17 10:05:02.800061: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-17 10:05:06.196429: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133/133 [==============================] - 15s 44ms/step - loss: 1.8809 - acc: 0.2711 - val_loss: 1.3466 - val_acc: 0.4400\n",
      "Epoch 2/100\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 1.0412 - acc: 0.5718 - val_loss: 0.9085 - val_acc: 0.6307\n",
      "Epoch 3/100\n",
      "133/133 [==============================] - 4s 32ms/step - loss: 0.7358 - acc: 0.7047 - val_loss: 0.6663 - val_acc: 0.7320\n",
      "Epoch 4/100\n",
      "133/133 [==============================] - 4s 30ms/step - loss: 0.6213 - acc: 0.7600 - val_loss: 0.6004 - val_acc: 0.7733\n",
      "Epoch 5/100\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 0.5706 - acc: 0.7842 - val_loss: 0.5961 - val_acc: 0.7613\n",
      "Epoch 6/100\n",
      "133/133 [==============================] - 4s 32ms/step - loss: 0.5545 - acc: 0.7852 - val_loss: 0.5854 - val_acc: 0.7787\n",
      "Epoch 7/100\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 0.5236 - acc: 0.8052 - val_loss: 0.5388 - val_acc: 0.8093\n",
      "Epoch 8/100\n",
      "133/133 [==============================] - 5s 36ms/step - loss: 0.5191 - acc: 0.8035 - val_loss: 0.5748 - val_acc: 0.7573\n",
      "Epoch 9/100\n",
      "133/133 [==============================] - 4s 31ms/step - loss: 0.4967 - acc: 0.8141 - val_loss: 0.5892 - val_acc: 0.7853\n",
      "Epoch 10/100\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 0.4969 - acc: 0.8134 - val_loss: 0.5376 - val_acc: 0.7973\n",
      "Epoch 11/100\n",
      "133/133 [==============================] - 4s 32ms/step - loss: 0.4863 - acc: 0.8169 - val_loss: 0.5528 - val_acc: 0.7827\n",
      "Epoch 12/100\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 0.4795 - acc: 0.8214 - val_loss: 0.5356 - val_acc: 0.7987\n",
      "Epoch 13/100\n",
      "133/133 [==============================] - 4s 28ms/step - loss: 0.4644 - acc: 0.8268 - val_loss: 0.5481 - val_acc: 0.7853\n",
      "Epoch 14/100\n",
      "133/133 [==============================] - 4s 32ms/step - loss: 0.4668 - acc: 0.8219 - val_loss: 0.5230 - val_acc: 0.8093\n",
      "Epoch 15/100\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 0.4658 - acc: 0.8268 - val_loss: 0.5699 - val_acc: 0.8080\n",
      "Epoch 16/100\n",
      "133/133 [==============================] - 5s 38ms/step - loss: 0.4722 - acc: 0.8200 - val_loss: 0.5639 - val_acc: 0.7920\n",
      "Epoch 17/100\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 0.4517 - acc: 0.8320 - val_loss: 0.5135 - val_acc: 0.8093\n",
      "Epoch 18/100\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 0.4438 - acc: 0.8353 - val_loss: 0.5163 - val_acc: 0.8173\n",
      "Epoch 19/100\n",
      "133/133 [==============================] - 4s 31ms/step - loss: 0.4508 - acc: 0.8285 - val_loss: 0.5397 - val_acc: 0.8027\n",
      "Epoch 20/100\n",
      "133/133 [==============================] - 4s 28ms/step - loss: 0.4418 - acc: 0.8311 - val_loss: 0.5177 - val_acc: 0.8160\n",
      "Epoch 21/100\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 0.4409 - acc: 0.8336 - val_loss: 0.5576 - val_acc: 0.8120\n",
      "Epoch 22/100\n",
      "133/133 [==============================] - 4s 31ms/step - loss: 0.4419 - acc: 0.8360 - val_loss: 0.5564 - val_acc: 0.7933\n",
      "Epoch 23/100\n",
      "133/133 [==============================] - 4s 32ms/step - loss: 0.4265 - acc: 0.8362 - val_loss: 0.5245 - val_acc: 0.8133\n",
      "Epoch 24/100\n",
      "133/133 [==============================] - 5s 34ms/step - loss: 0.4305 - acc: 0.8360 - val_loss: 0.5413 - val_acc: 0.8040\n",
      "Epoch 25/100\n",
      "133/133 [==============================] - 4s 31ms/step - loss: 0.4240 - acc: 0.8358 - val_loss: 0.5443 - val_acc: 0.8173\n",
      "Epoch 26/100\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 0.4139 - acc: 0.8398 - val_loss: 0.5320 - val_acc: 0.8107\n",
      "Epoch 27/100\n",
      "133/133 [==============================] - 4s 33ms/step - loss: 0.4208 - acc: 0.8386 - val_loss: 0.5325 - val_acc: 0.8080\n",
      "Epoch 28/100\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 0.3884 - acc: 0.8504 - val_loss: 0.5283 - val_acc: 0.8187\n",
      "Epoch 29/100\n",
      "133/133 [==============================] - 5s 36ms/step - loss: 0.3758 - acc: 0.8508 - val_loss: 0.5422 - val_acc: 0.8173\n",
      "Epoch 30/100\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 0.3677 - acc: 0.8525 - val_loss: 0.5412 - val_acc: 0.8213\n",
      "Epoch 31/100\n",
      "133/133 [==============================] - 5s 34ms/step - loss: 0.3568 - acc: 0.8506 - val_loss: 0.5499 - val_acc: 0.8173\n",
      "Epoch 32/100\n",
      "133/133 [==============================] - 5s 35ms/step - loss: 0.3639 - acc: 0.8551 - val_loss: 0.5459 - val_acc: 0.8120\n",
      "Epoch 33/100\n",
      "133/133 [==============================] - 4s 30ms/step - loss: 0.3583 - acc: 0.8558 - val_loss: 0.5518 - val_acc: 0.8160\n",
      "Epoch 34/100\n",
      "133/133 [==============================] - 4s 32ms/step - loss: 0.3478 - acc: 0.8569 - val_loss: 0.5543 - val_acc: 0.8120\n",
      "Epoch 35/100\n",
      "133/133 [==============================] - 4s 28ms/step - loss: 0.3427 - acc: 0.8565 - val_loss: 0.5894 - val_acc: 0.8147\n",
      "Epoch 36/100\n",
      "133/133 [==============================] - 4s 28ms/step - loss: 0.3475 - acc: 0.8612 - val_loss: 0.5868 - val_acc: 0.8053\n",
      "Epoch 37/100\n",
      "133/133 [==============================] - 4s 32ms/step - loss: 0.3438 - acc: 0.8569 - val_loss: 0.6045 - val_acc: 0.8080\n",
      "Epoch 38/100\n",
      "133/133 [==============================] - 5s 34ms/step - loss: 0.3379 - acc: 0.8595 - val_loss: 0.5783 - val_acc: 0.8093\n",
      "Epoch 39/100\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 0.3418 - acc: 0.8602 - val_loss: 0.5701 - val_acc: 0.8160\n",
      "Epoch 40/100\n",
      "133/133 [==============================] - 4s 32ms/step - loss: 0.3336 - acc: 0.8607 - val_loss: 0.5687 - val_acc: 0.8200\n",
      "Epoch 41/100\n",
      "133/133 [==============================] - 4s 30ms/step - loss: 0.3339 - acc: 0.8607 - val_loss: 0.5766 - val_acc: 0.8200\n",
      "Epoch 42/100\n",
      "133/133 [==============================] - 4s 32ms/step - loss: 0.3367 - acc: 0.8616 - val_loss: 0.5828 - val_acc: 0.8093\n",
      "Epoch 43/100\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 0.3288 - acc: 0.8642 - val_loss: 0.5963 - val_acc: 0.8160\n",
      "Epoch 44/100\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 0.3337 - acc: 0.8588 - val_loss: 0.5752 - val_acc: 0.8107\n",
      "Epoch 45/100\n",
      "133/133 [==============================] - 4s 33ms/step - loss: 0.3300 - acc: 0.8635 - val_loss: 0.5852 - val_acc: 0.8120\n",
      "Epoch 46/100\n",
      "133/133 [==============================] - 5s 35ms/step - loss: 0.3337 - acc: 0.8631 - val_loss: 0.5790 - val_acc: 0.8173\n",
      "Epoch 47/100\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 0.3374 - acc: 0.8607 - val_loss: 0.5805 - val_acc: 0.8093\n",
      "Epoch 48/100\n",
      "133/133 [==============================] - 4s 33ms/step - loss: 0.3232 - acc: 0.8640 - val_loss: 0.5995 - val_acc: 0.8053\n",
      "Epoch 49/100\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 0.3258 - acc: 0.8664 - val_loss: 0.5942 - val_acc: 0.8120\n",
      "Epoch 50/100\n",
      "133/133 [==============================] - 4s 32ms/step - loss: 0.3275 - acc: 0.8631 - val_loss: 0.6013 - val_acc: 0.8040\n",
      "Epoch 51/100\n",
      "133/133 [==============================] - 4s 28ms/step - loss: 0.3286 - acc: 0.8652 - val_loss: 0.5894 - val_acc: 0.8120\n",
      "Epoch 52/100\n",
      "133/133 [==============================] - 4s 28ms/step - loss: 0.3302 - acc: 0.8649 - val_loss: 0.5779 - val_acc: 0.8080\n",
      "Epoch 53/100\n",
      "133/133 [==============================] - 4s 32ms/step - loss: 0.3319 - acc: 0.8635 - val_loss: 0.5886 - val_acc: 0.8053\n",
      "Epoch 54/100\n",
      "133/133 [==============================] - 5s 36ms/step - loss: 0.3340 - acc: 0.8631 - val_loss: 0.5802 - val_acc: 0.8067\n",
      "Epoch 55/100\n",
      "133/133 [==============================] - 4s 28ms/step - loss: 0.3307 - acc: 0.8635 - val_loss: 0.5876 - val_acc: 0.8107\n",
      "Epoch 56/100\n",
      "133/133 [==============================] - 5s 34ms/step - loss: 0.3269 - acc: 0.8633 - val_loss: 0.5874 - val_acc: 0.8173\n",
      "Epoch 57/100\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 0.3227 - acc: 0.8678 - val_loss: 0.6021 - val_acc: 0.8053\n",
      "Epoch 58/100\n",
      "133/133 [==============================] - 4s 31ms/step - loss: 0.3267 - acc: 0.8656 - val_loss: 0.5853 - val_acc: 0.8173\n",
      "Epoch 59/100\n",
      "133/133 [==============================] - 4s 28ms/step - loss: 0.3257 - acc: 0.8635 - val_loss: 0.5649 - val_acc: 0.8107\n",
      "Epoch 60/100\n",
      "133/133 [==============================] - 4s 28ms/step - loss: 0.3376 - acc: 0.8605 - val_loss: 0.5819 - val_acc: 0.8107\n",
      "Epoch 61/100\n",
      "133/133 [==============================] - 5s 37ms/step - loss: 0.3268 - acc: 0.8656 - val_loss: 0.5977 - val_acc: 0.8107\n",
      "Epoch 62/100\n",
      "133/133 [==============================] - 4s 28ms/step - loss: 0.3393 - acc: 0.8628 - val_loss: 0.5887 - val_acc: 0.8107\n",
      "Epoch 63/100\n",
      "133/133 [==============================] - 4s 30ms/step - loss: 0.3323 - acc: 0.8616 - val_loss: 0.5778 - val_acc: 0.8253\n",
      "Epoch 64/100\n",
      "133/133 [==============================] - 4s 31ms/step - loss: 0.3260 - acc: 0.8628 - val_loss: 0.5952 - val_acc: 0.8053\n",
      "Epoch 65/100\n",
      "133/133 [==============================] - 4s 28ms/step - loss: 0.3257 - acc: 0.8668 - val_loss: 0.6198 - val_acc: 0.8147\n",
      "Epoch 66/100\n",
      "133/133 [==============================] - 4s 31ms/step - loss: 0.3244 - acc: 0.8671 - val_loss: 0.5679 - val_acc: 0.8173\n",
      "Epoch 67/100\n",
      "133/133 [==============================] - 4s 28ms/step - loss: 0.3256 - acc: 0.8661 - val_loss: 0.5753 - val_acc: 0.8133\n",
      "Epoch 68/100\n",
      "133/133 [==============================] - 4s 28ms/step - loss: 0.3258 - acc: 0.8645 - val_loss: 0.5832 - val_acc: 0.8133\n",
      "Epoch 69/100\n",
      "133/133 [==============================] - 5s 37ms/step - loss: 0.3327 - acc: 0.8609 - val_loss: 0.5700 - val_acc: 0.8147\n",
      "Epoch 70/100\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 0.3281 - acc: 0.8635 - val_loss: 0.5905 - val_acc: 0.8120\n",
      "Epoch 71/100\n",
      "133/133 [==============================] - 4s 31ms/step - loss: 0.3372 - acc: 0.8605 - val_loss: 0.5923 - val_acc: 0.8093\n",
      "Epoch 72/100\n",
      "133/133 [==============================] - 4s 32ms/step - loss: 0.3328 - acc: 0.8609 - val_loss: 0.5654 - val_acc: 0.8147\n",
      "Epoch 73/100\n",
      "133/133 [==============================] - 4s 28ms/step - loss: 0.3300 - acc: 0.8614 - val_loss: 0.6185 - val_acc: 0.8067\n",
      "Epoch 74/100\n",
      "133/133 [==============================] - 4s 34ms/step - loss: 0.3342 - acc: 0.8640 - val_loss: 0.5957 - val_acc: 0.8067\n",
      "Epoch 75/100\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 0.3292 - acc: 0.8628 - val_loss: 0.6059 - val_acc: 0.8080\n",
      "Epoch 76/100\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 0.3324 - acc: 0.8633 - val_loss: 0.5814 - val_acc: 0.8107\n",
      "Epoch 77/100\n",
      "133/133 [==============================] - 5s 37ms/step - loss: 0.3250 - acc: 0.8652 - val_loss: 0.5935 - val_acc: 0.8160\n",
      "Epoch 78/100\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 0.3349 - acc: 0.8614 - val_loss: 0.5868 - val_acc: 0.8093\n",
      "Epoch 79/100\n",
      "133/133 [==============================] - 4s 30ms/step - loss: 0.3270 - acc: 0.8614 - val_loss: 0.5776 - val_acc: 0.8093\n",
      "Epoch 80/100\n",
      "133/133 [==============================] - 4s 28ms/step - loss: 0.3319 - acc: 0.8664 - val_loss: 0.5802 - val_acc: 0.8133\n",
      "Epoch 81/100\n",
      "133/133 [==============================] - 4s 28ms/step - loss: 0.3309 - acc: 0.8633 - val_loss: 0.5832 - val_acc: 0.8160\n",
      "Epoch 82/100\n",
      "133/133 [==============================] - 4s 31ms/step - loss: 0.3360 - acc: 0.8607 - val_loss: 0.5804 - val_acc: 0.8107\n",
      "Epoch 83/100\n",
      "133/133 [==============================] - 4s 28ms/step - loss: 0.3344 - acc: 0.8638 - val_loss: 0.5795 - val_acc: 0.8200\n",
      "Epoch 84/100\n",
      "133/133 [==============================] - 4s 28ms/step - loss: 0.3305 - acc: 0.8647 - val_loss: 0.5866 - val_acc: 0.8080\n",
      "Epoch 85/100\n",
      "133/133 [==============================] - 5s 40ms/step - loss: 0.3369 - acc: 0.8602 - val_loss: 0.5742 - val_acc: 0.8067\n",
      "Epoch 86/100\n",
      "133/133 [==============================] - 4s 28ms/step - loss: 0.3365 - acc: 0.8607 - val_loss: 0.5781 - val_acc: 0.8200\n",
      "Epoch 87/100\n",
      "133/133 [==============================] - 4s 28ms/step - loss: 0.3270 - acc: 0.8659 - val_loss: 0.5628 - val_acc: 0.8147\n",
      "Epoch 88/100\n",
      "133/133 [==============================] - 4s 31ms/step - loss: 0.3333 - acc: 0.8612 - val_loss: 0.5940 - val_acc: 0.8173\n",
      "Epoch 89/100\n",
      "133/133 [==============================] - 4s 28ms/step - loss: 0.3340 - acc: 0.8612 - val_loss: 0.5894 - val_acc: 0.8067\n",
      "Epoch 90/100\n",
      "133/133 [==============================] - 4s 31ms/step - loss: 0.3368 - acc: 0.8614 - val_loss: 0.5934 - val_acc: 0.8147\n",
      "Epoch 91/100\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 0.3321 - acc: 0.8628 - val_loss: 0.5897 - val_acc: 0.8120\n",
      "Epoch 92/100\n",
      "133/133 [==============================] - 4s 30ms/step - loss: 0.3286 - acc: 0.8633 - val_loss: 0.5702 - val_acc: 0.8080\n",
      "Epoch 93/100\n",
      "133/133 [==============================] - 4s 33ms/step - loss: 0.3319 - acc: 0.8612 - val_loss: 0.5976 - val_acc: 0.8120\n",
      "Epoch 94/100\n",
      "133/133 [==============================] - 4s 28ms/step - loss: 0.3323 - acc: 0.8640 - val_loss: 0.5725 - val_acc: 0.8187\n",
      "Epoch 95/100\n",
      "133/133 [==============================] - 4s 28ms/step - loss: 0.3298 - acc: 0.8624 - val_loss: 0.5865 - val_acc: 0.8080\n",
      "Epoch 96/100\n",
      "133/133 [==============================] - 4s 32ms/step - loss: 0.3323 - acc: 0.8607 - val_loss: 0.5991 - val_acc: 0.8173\n",
      "Epoch 97/100\n",
      "133/133 [==============================] - 4s 28ms/step - loss: 0.3326 - acc: 0.8614 - val_loss: 0.5983 - val_acc: 0.8067\n",
      "Epoch 98/100\n",
      "133/133 [==============================] - 4s 31ms/step - loss: 0.3330 - acc: 0.8638 - val_loss: 0.5696 - val_acc: 0.8267\n",
      "Epoch 99/100\n",
      "133/133 [==============================] - 4s 28ms/step - loss: 0.3297 - acc: 0.8626 - val_loss: 0.5960 - val_acc: 0.8093\n",
      "Epoch 100/100\n",
      "133/133 [==============================] - 5s 34ms/step - loss: 0.3260 - acc: 0.8652 - val_loss: 0.5692 - val_acc: 0.8107\n"
     ]
    }
   ],
   "source": [
    "callbacks = myCallback()\n",
    "batch_size=5\n",
    "FAST_RUN = False\n",
    "epochs=20 if FAST_RUN else 100\n",
    "history = model0.fit_generator(\n",
    "    train_generator, \n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[\n",
    "        ks.callbacks.ReduceLROnPlateau(), \n",
    "        callbacks\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "777b829c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-17T10:12:10.945468Z",
     "iopub.status.busy": "2022-09-17T10:12:10.945041Z",
     "iopub.status.idle": "2022-09-17T10:12:11.228831Z",
     "shell.execute_reply": "2022-09-17T10:12:11.227599Z"
    },
    "papermill": {
     "duration": 0.624229,
     "end_time": "2022-09-17T10:12:11.231308",
     "exception": false,
     "start_time": "2022-09-17T10:12:10.607079",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_train = history.history['loss']\n",
    "loss_val = history.history['val_loss']\n",
    "epochs = range(1,101)\n",
    "plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
    "plt.plot(epochs, loss_val, 'b', label='validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06e3b75e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-17T10:12:12.361624Z",
     "iopub.status.busy": "2022-09-17T10:12:12.361167Z",
     "iopub.status.idle": "2022-09-17T10:12:12.513915Z",
     "shell.execute_reply": "2022-09-17T10:12:12.512591Z"
    },
    "papermill": {
     "duration": 0.617303,
     "end_time": "2022-09-17T10:12:12.516871",
     "exception": false,
     "start_time": "2022-09-17T10:12:11.899568",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model0_regularized = ks.models.Sequential()\n",
    "model0_regularized.add(ks.layers.Dense(4, input_shape=(64, 64, 1), kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))) #units=4(we define how many outputs we want)\n",
    "model0_regularized.add(ks.layers.Dense(8, input_shape=(64, 64, 1), kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
    "model0_regularized.add(ks.layers.Dense(8, input_shape=(64, 64, 1), kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
    "model0_regularized.add(ks.layers.Conv2D(64,(3, 3), activation='relu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))) \n",
    "\n",
    "model0_regularized.add(ks.layers.MaxPooling2D(pool_size=2, strides=2))\n",
    "model0_regularized.add(ks.layers.Conv2D(128, (3, 3), activation='relu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
    "model0_regularized.add(ks.layers.MaxPooling2D((2, 2))) \n",
    "       \n",
    "model0_regularized.add(ks.layers.Conv2D(256, (3, 3), activation='relu', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n",
    "model0_regularized.add(ks.layers.MaxPooling2D(2, 2))\n",
    "model0_regularized.add(ks.layers.Conv2D(512, (3, 3), activation='relu'))\n",
    "model0_regularized.add(ks.layers.MaxPooling2D(2, 2))\n",
    "model0_regularized.add(ks.layers.Dropout(0.2))\n",
    "model0_regularized.add(ks.layers.Flatten())\n",
    "\n",
    "model0_regularized.add(ks.layers.Dense(1024, activation='relu', kernel_regularizer=l2(0.01) , bias_regularizer=l2(0.01)))\n",
    "model0_regularized.add(ks.layers.Dense(10, activation='softmax', kernel_regularizer=l2(0.01) ,  bias_regularizer=l2(0.01)))\n",
    "#i'm not sure about flatten maxpooling2d\n",
    "\n",
    "model0_regularized.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "                      # max pooling error for L2 regularization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e86926b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-17T10:12:13.187219Z",
     "iopub.status.busy": "2022-09-17T10:12:13.186771Z",
     "iopub.status.idle": "2022-09-17T10:12:13.199227Z",
     "shell.execute_reply": "2022-09-17T10:12:13.197920Z"
    },
    "papermill": {
     "duration": 0.35628,
     "end_time": "2022-09-17T10:12:13.202160",
     "exception": false,
     "start_time": "2022-09-17T10:12:12.845880",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model0_regularized.compile(optimizer=ks.optimizers.Adam(),loss='categorical_crossentropy',metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1836b014",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-17T10:12:13.907499Z",
     "iopub.status.busy": "2022-09-17T10:12:13.905610Z",
     "iopub.status.idle": "2022-09-17T10:19:22.111911Z",
     "shell.execute_reply": "2022-09-17T10:19:22.110596Z"
    },
    "papermill": {
     "duration": 428.564222,
     "end_time": "2022-09-17T10:19:22.115095",
     "exception": false,
     "start_time": "2022-09-17T10:12:13.550873",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "133/133 [==============================] - 6s 32ms/step - loss: 4.1011 - acc: 0.1165 - val_loss: 2.4035 - val_acc: 0.1413\n",
      "Epoch 2/100\n",
      "133/133 [==============================] - 4s 32ms/step - loss: 2.3741 - acc: 0.1144 - val_loss: 2.3528 - val_acc: 0.1173\n",
      "Epoch 3/100\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 2.3399 - acc: 0.1129 - val_loss: 2.3293 - val_acc: 0.1173\n",
      "Epoch 4/100\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 2.3221 - acc: 0.1129 - val_loss: 2.3163 - val_acc: 0.1173\n",
      "Epoch 5/100\n",
      "133/133 [==============================] - 4s 32ms/step - loss: 2.3122 - acc: 0.1129 - val_loss: 2.3092 - val_acc: 0.1173\n",
      "Epoch 6/100\n",
      "133/133 [==============================] - 5s 34ms/step - loss: 2.3068 - acc: 0.1129 - val_loss: 2.3055 - val_acc: 0.1173\n",
      "Epoch 7/100\n",
      "133/133 [==============================] - 5s 35ms/step - loss: 2.3039 - acc: 0.1129 - val_loss: 2.3034 - val_acc: 0.1173\n",
      "Epoch 8/100\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 2.3024 - acc: 0.1129 - val_loss: 2.3022 - val_acc: 0.1173\n",
      "Epoch 9/100\n",
      "133/133 [==============================] - 4s 28ms/step - loss: 2.3015 - acc: 0.1129 - val_loss: 2.3016 - val_acc: 0.1173\n",
      "Epoch 10/100\n",
      "133/133 [==============================] - 4s 32ms/step - loss: 2.3010 - acc: 0.1129 - val_loss: 2.3016 - val_acc: 0.1173\n",
      "Epoch 11/100\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 2.3008 - acc: 0.1129 - val_loss: 2.3013 - val_acc: 0.1173\n",
      "Epoch 12/100\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 2.3007 - acc: 0.1129 - val_loss: 2.3011 - val_acc: 0.1173\n",
      "Epoch 13/100\n",
      "133/133 [==============================] - 4s 32ms/step - loss: 2.3005 - acc: 0.1129 - val_loss: 2.3011 - val_acc: 0.1173\n",
      "Epoch 14/100\n",
      "133/133 [==============================] - 5s 34ms/step - loss: 2.3005 - acc: 0.1129 - val_loss: 2.3011 - val_acc: 0.1173\n",
      "Epoch 15/100\n",
      "133/133 [==============================] - 5s 34ms/step - loss: 2.3006 - acc: 0.1129 - val_loss: 2.3011 - val_acc: 0.1173\n",
      "Epoch 16/100\n",
      "133/133 [==============================] - 4s 28ms/step - loss: 2.3006 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 17/100\n",
      "133/133 [==============================] - 4s 28ms/step - loss: 2.3005 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 18/100\n",
      "133/133 [==============================] - 4s 32ms/step - loss: 2.3005 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 19/100\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 2.3005 - acc: 0.1129 - val_loss: 2.3011 - val_acc: 0.1173\n",
      "Epoch 20/100\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 2.3005 - acc: 0.1129 - val_loss: 2.3011 - val_acc: 0.1173\n",
      "Epoch 21/100\n",
      "133/133 [==============================] - 4s 32ms/step - loss: 2.3005 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 22/100\n",
      "133/133 [==============================] - 5s 36ms/step - loss: 2.3005 - acc: 0.1129 - val_loss: 2.3013 - val_acc: 0.1173\n",
      "Epoch 23/100\n",
      "133/133 [==============================] - 4s 32ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 24/100\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 25/100\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 26/100\n",
      "133/133 [==============================] - 4s 32ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 27/100\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 28/100\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 29/100\n",
      "133/133 [==============================] - 5s 37ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 30/100\n",
      "133/133 [==============================] - 4s 32ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 31/100\n",
      "133/133 [==============================] - 4s 32ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 32/100\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 33/100\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 34/100\n",
      "133/133 [==============================] - 4s 32ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 35/100\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 36/100\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 37/100\n",
      "133/133 [==============================] - 5s 41ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 38/100\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 39/100\n",
      "133/133 [==============================] - 4s 32ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 40/100\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 41/100\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 42/100\n",
      "133/133 [==============================] - 4s 34ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 43/100\n",
      "133/133 [==============================] - 4s 30ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 44/100\n",
      "133/133 [==============================] - 5s 34ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 45/100\n",
      "133/133 [==============================] - 4s 31ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 46/100\n",
      "133/133 [==============================] - 4s 28ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 47/100\n",
      "133/133 [==============================] - 4s 31ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 48/100\n",
      "133/133 [==============================] - 4s 28ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 49/100\n",
      "133/133 [==============================] - 4s 32ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 50/100\n",
      "133/133 [==============================] - 4s 28ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 51/100\n",
      "133/133 [==============================] - 4s 28ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 52/100\n",
      "133/133 [==============================] - 6s 41ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 53/100\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 54/100\n",
      "133/133 [==============================] - 4s 28ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 55/100\n",
      "133/133 [==============================] - 4s 32ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 56/100\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 57/100\n",
      "133/133 [==============================] - 4s 32ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 58/100\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 59/100\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 60/100\n",
      "133/133 [==============================] - 5s 36ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 61/100\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 62/100\n",
      "133/133 [==============================] - 4s 32ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 63/100\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 64/100\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 65/100\n",
      "133/133 [==============================] - 4s 32ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 66/100\n",
      "133/133 [==============================] - 4s 28ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 67/100\n",
      "133/133 [==============================] - 5s 39ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 68/100\n",
      "133/133 [==============================] - 4s 28ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 69/100\n",
      "133/133 [==============================] - 4s 32ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 70/100\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 71/100\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 72/100\n",
      "133/133 [==============================] - 4s 32ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 73/100\n",
      "133/133 [==============================] - 5s 35ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 74/100\n",
      "133/133 [==============================] - 4s 33ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 75/100\n",
      "133/133 [==============================] - 4s 28ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 76/100\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 77/100\n",
      "133/133 [==============================] - 4s 32ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 78/100\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 79/100\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 80/100\n",
      "133/133 [==============================] - 4s 32ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 81/100\n",
      "133/133 [==============================] - 5s 39ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 82/100\n",
      "133/133 [==============================] - 4s 32ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 83/100\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 84/100\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 85/100\n",
      "133/133 [==============================] - 4s 32ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 86/100\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 87/100\n",
      "133/133 [==============================] - 4s 31ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 88/100\n",
      "133/133 [==============================] - 5s 34ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 89/100\n",
      "133/133 [==============================] - 4s 32ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 90/100\n",
      "133/133 [==============================] - 4s 31ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 91/100\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 92/100\n",
      "133/133 [==============================] - 4s 32ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 93/100\n",
      "133/133 [==============================] - 4s 31ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 94/100\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 95/100\n",
      "133/133 [==============================] - 4s 32ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 96/100\n",
      "133/133 [==============================] - 5s 39ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 97/100\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 98/100\n",
      "133/133 [==============================] - 4s 32ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 99/100\n",
      "133/133 [==============================] - 4s 29ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n",
      "Epoch 100/100\n",
      "133/133 [==============================] - 4s 32ms/step - loss: 2.3003 - acc: 0.1129 - val_loss: 2.3012 - val_acc: 0.1173\n"
     ]
    }
   ],
   "source": [
    "callbacks = myCallback()\n",
    "batch_size=5\n",
    "FAST_RUN = False\n",
    "epochs=20 if FAST_RUN else 100\n",
    "history = model0_regularized.fit_generator(\n",
    "    train_generator, \n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[\n",
    "        ks.callbacks.ReduceLROnPlateau()\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8dd60d08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-17T10:19:23.544907Z",
     "iopub.status.busy": "2022-09-17T10:19:23.543634Z",
     "iopub.status.idle": "2022-09-17T10:19:23.800624Z",
     "shell.execute_reply": "2022-09-17T10:19:23.798888Z"
    },
    "papermill": {
     "duration": 0.959565,
     "end_time": "2022-09-17T10:19:23.803659",
     "exception": false,
     "start_time": "2022-09-17T10:19:22.844094",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_train = history.history['loss']\n",
    "loss_val = history.history['val_loss']\n",
    "epochs = range(1,101)\n",
    "plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
    "plt.plot(epochs, loss_val, 'b', label='validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d245dc8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-17T10:19:25.226031Z",
     "iopub.status.busy": "2022-09-17T10:19:25.225316Z",
     "iopub.status.idle": "2022-09-17T10:19:25.460468Z",
     "shell.execute_reply": "2022-09-17T10:19:25.459125Z"
    },
    "papermill": {
     "duration": 0.910061,
     "end_time": "2022-09-17T10:19:25.463214",
     "exception": false,
     "start_time": "2022-09-17T10:19:24.553153",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_train = history.history['loss']\n",
    "epochs = range(1,101)\n",
    "plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
    "plt.title('Training loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6377633c",
   "metadata": {
    "papermill": {
     "duration": 0.688699,
     "end_time": "2022-09-17T10:19:26.882320",
     "exception": false,
     "start_time": "2022-09-17T10:19:26.193621",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# L2 Regularization (for Machine learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df4aede",
   "metadata": {
    "papermill": {
     "duration": 0.713668,
     "end_time": "2022-09-17T10:19:28.319398",
     "exception": false,
     "start_time": "2022-09-17T10:19:27.605730",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "A regression model that uses **L1 regularization** technique is called **Lasso Regression** and model which uses **L2** is called **Ridge Regression.**  \n",
    "The key difference between these two is the penalty term.\n",
    "Traditional methods like cross-validation, stepwise regression to handle overfitting and perform feature selection work well with a small set of features but these techniques are a great alternative when we are dealing with **a large set of features.**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb092f5f",
   "metadata": {
    "papermill": {
     "duration": 0.718204,
     "end_time": "2022-09-17T10:19:29.732341",
     "exception": false,
     "start_time": "2022-09-17T10:19:29.014137",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "If you have studied the concept of regularization in machine learning, you will have a fair idea that regularization penalizes the coefficients. In deep learning, it actually penalizes the weight matrices of the nodes.\n",
    "\n",
    "Assume that our regularization coefficient is so high that some of the weight matrices are nearly equal to zero. This will result in a much simpler linear network and slight underfitting of the training data.\n",
    "\n",
    "Such a large value of the regularization coefficient is not that useful. We need to optimize the value of regularization coefficient in order to obtain a well-fitted model as shown in the image below.  \n",
    "\n",
    "**Variables standardization** is the initial procedure in ridge regression. Both the independent and dependent variables require standardization through subtraction of their averages and a division of the result with the standard deviations. It is common practice to annotate in a formula whether the variables therein are standardized or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6b72c9",
   "metadata": {
    "papermill": {
     "duration": 0.718956,
     "end_time": "2022-09-17T10:19:31.135118",
     "exception": false,
     "start_time": "2022-09-17T10:19:30.416162",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "regularizing lamba part is in progress ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a799ab",
   "metadata": {
    "papermill": {
     "duration": 0.731133,
     "end_time": "2022-09-17T10:19:32.957746",
     "exception": false,
     "start_time": "2022-09-17T10:19:32.226613",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "To find optimum alpha for Ridge Regularization we can be applying GridSearchCV"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 906.543677,
   "end_time": "2022-09-17T10:19:37.406617",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-09-17T10:04:30.862940",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
